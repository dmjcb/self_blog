---
title: "libtorch开发"
date: 2024-12-25
categories: [ai]
tags: [ai]
excerpt: "pytorch概念"
---

[交叉编译pytorch的aarch64版本](https://blog.csdn.net/GGGddw/article/details/127986737)
[利用PyTorch C++ API（LibTorch）加载预训练模型及预测](https://blog.csdn.net/weixin_44278406/article/details/103637160)

## 交叉构建

### 源码构建

根目录下创建交叉编译工具链

```cmake
# aarch64_build.cmake
set(CMAKE_SYSTEM_NAME Linux)
set(CMAKE_SYSTEM_PROCESSOR aarch64)
set(CMAKE_TRY_COMPILE_TARGET_TYPE "STATIC_LIBRARY")
set(CMAKE_C_COMPILER /usr/bin/aarch64-linux-gnu-gcc)
set(CMAKE_CXX_COMPILER /usr/bin/aarch64-linux-gnu-g++)
set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -fopenmp")
set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -I${CMAKE_SOURCE_DIR}/third_party/sleef/_host/include")
```

预编译出protoc库和sleef库

```sh
./scripts/build_host_protoc.sh
```

```sh
cd third_party/sleef/_host

cmake -G "Unix Makefiles" -DCMAKE_INSTALL_PREFIX=_install -DCMAKE_BUILD_TYPE=Release -DBUILD_TESTS=OFF ../

make
```

```sh
cmake --build third_party/sleef/_host
```

```sh
mkdir pytorch-build-arm64 && cd pytorch-build-arm64

cmake -DBUILD_SHARED_LIBS:BOOL=ON -DCMAKE_TOOLCHAIN_FILE=aarch64_build.cmake -DUSE_MKLDNN=OFF -DUSE_QNNPACK=OFF -DUSE_PYTORCH_QNNPACK=OFF -DBUILD_TEST=OFF -DUSE_NNPACK=OFF -DCAFFE2_CUSTOM_PROTOC_EXECUTABLE=$HOME/pytorch/build_host_protoc/bin/protoc -DNATIVE_BUILD_DIR=$HOME/pytorch/third_party/sleef/_host -DCMAKE_BUILD_TYPE:STRING=Release -DPYTHON_EXECUTABLE:PATH="/usr/bin/python3" -DCMAKE_INSTALL_PREFIX:PATH=install_aarch64 ../

cmake --build . --target install
```

### docker构建

```docker
# 使用 ARM64 架构的基础镜像
FROM arm64v8/gcc:12

# 设置环境变量
ENV DEBIAN_FRONTEND=noninteractive

# 更换 APT 镜像源为清华大学的镜像源
RUN cp /etc/apt/sources.list /etc/apt/sources.list.bak && \
    sed -i 's|http://archive.ubuntu.com/ubuntu/|https://mirrors.tuna.tsinghua.edu.cn/ubuntu/|g' /etc/apt/sources.list && \
    sed -i 's|http://security.ubuntu.com/ubuntu/|https://mirrors.tuna.tsinghua.edu.cn/ubuntu/|g' /etc/apt/sources.list && \
    apt-get update && apt-get upgrade -y

# 更新并安装必要的依赖项
RUN apt-get update && apt-get install -y \
    build-essential \
    gcc-aarch64-linux-gnu \
    g++-aarch64-linux-gnu \
    cmake \
    python3.8 \
    python3.8-dev \
    python3-pip \
    wget \
    curl \
    gnupg \
    ca-certificates \
    unzip \
    git \
    lsb-release \
    && rm -rf /var/lib/apt/lists/*

# 安装 CMake 3.31 版本
RUN wget https://cmake.org/files/v3.31/cmake-3.31.0-Linux-aarch64.tar.gz \
    && tar -xzvf cmake-3.31.0-Linux-aarch64.tar.gz \
    && mv cmake-3.31.0-Linux-aarch64 /opt/cmake \
    && ln -s /opt/cmake/bin/cmake /usr/local/bin/cmake \
    && rm cmake-3.31.0-Linux-aarch64.tar.gz

# 确保 python3.8 作为默认 Python 版本
RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1 \
    && update-alternatives --install /usr/bin/pip pip /usr/bin/pip3 1

# 确保 pip 最新
RUN pip install --upgrade pip

# 安装常用 Python 包
RUN pip install numpy scipy

# 设置工作目录
WORKDIR /workspace

# 默认运行 bash
CMD ["/bin/bash"]
```

## 测试

### 将 YOLOv8 模型转换为 TorchScript 格式

使用 libtorch 编写一个加载 YOLOv8 模型并进行图片物品

YOLOv8 是用 PyTorch 编写, 因此可以使用 PyTorch 提供的工具将其转换为 TorchScript 模型

在 Python 中加载 YOLOv8 模型并转换为 TorchScript 格式

```py
import torch
from ultralytics import YOLO

# 加载 YOLOv8 模型
model = YOLO('yolov8.pt')  # 这里假设你已经有了一个YOLOv8的模型文件

# 将模型转为 TorchScript 格式
scripted_model = torch.jit.trace(model, torch.randn(1, 3, 640, 640))  # 输入一个虚拟的图像 tensor
scripted_model.save("yolov8_torchscript.pt")
```

### 编写 C++ 代码进行推理

在 C++ 中加载和运行 TorchScript 模型, 首先需要包含 libtorch 和 OpenCV 的相关头文件

以下是一个完整的 C++ 示例, 展示如何加载图像、加载 TorchScript 模型并进行推理

C++ 代码结构
main.cpp - 用于加载模型和进行推理
CMakeLists.txt - 用于 CMake 构建

```cmake
# CMakeLists.txt
cmake_minimum_required(VERSION 3.10)
project(YOLOv8_Detection)

# 设置 C++ 标准
set(CMAKE_CXX_STANDARD 14)

# 设置 libtorch 路径
set(Torch_DIR "/path/to/libtorch/share/cmake/Torch")

# 查找 libtorch 包
find_package(Torch REQUIRED)

# 包含 OpenCV 库
find_package(OpenCV REQUIRED)

# 设置可执行文件
add_executable(yolov8_inference main.cpp)

# 链接 libtorch 和 OpenCV 库
target_link_libraries(yolov8_inference "${TORCH_LIBRARIES}" "${OpenCV_LIBS}")
```

确保替换 /path/to/libtorch/ 为你实际安装的 libtorch 目录

main.cpp

以下是 C++ 代码, 展示了如何加载模型并进行物品识别

```c++
#include <torch/script.h> // One-stop header for loading TorchScript models.
#include <opencv2/opencv.hpp>
#include <iostream>
#include <memory>

// 显示物品检测结果
void showResults(const cv::Mat& img, const std::vector<cv::Rect>& boxes, const std::vector<float>& scores) {
    for (size_t i = 0; i < boxes.size(); ++i) {
        cv::rectangle(img, boxes[i], cv::Scalar(0, 255, 0), 2); // 绘制矩形框
        cv::putText(img, std::to_string(scores[i]), boxes[i].tl(), cv::FONT_HERSHEY_SIMPLEX, 1.0, cv::Scalar(0, 255, 0), 2);
    }
    cv::imshow("Detection Result", img);
    cv::waitKey(0);
}

int main() {
    // 加载 TorchScript 模型
    std::shared_ptr<torch::jit::script::Module> module;
    try {
        // 载入模型
        module = torch::jit::load("yolov8_torchscript.pt");
    } catch (const c10::Error& e) {
        std::cerr << "Error loading the model\n";
        return -1;
    }

    // 加载图像
    cv::Mat img = cv::imread("input.jpg");
    if (img.empty()) {
        std::cerr << "Could not open or find the image\n";
        return -1;
    }

    // 将图像转换为 640x640,  并转为浮动类型
    cv::Mat blob;
    cv::resize(img, img, cv::Size(640, 640));  // 调整图片大小为 640x640
    cv::cvtColor(img, img, cv::COLOR_BGR2RGB);  // 将 BGR 转为 RGB
    blob = cv::dnn::blobFromImage(img, 1.0, cv::Size(640, 640), cv::Scalar(0, 0, 0), true, false);

    // 将图片转为 Tensor
    torch::Tensor tensor_image = torch::from_blob(blob.data, {1, 3, 640, 640}, torch::kByte);
    tensor_image = tensor_image.to(torch::kFloat32);
    tensor_image = tensor_image.div(255.0);  // 标准化到 [0, 1]

    // 模型推理
    std::vector<torch::jit::IValue> inputs;
    inputs.push_back(tensor_image);

    // 获取推理结果
    at::Tensor output = module->forward(inputs).toTensor();

    // 输出处理: 此处需要根据模型输出的格式进行处理(例如获取边界框、置信度等)
    // 例如, 假设模型输出是 (1, 25200, 85) 的张量, 其中包含边界框、类别标签和置信度

    // 假设输出是一个二维 Tensor, 格式为 (num_boxes, 85)
    // 这里需要根据 YOLOv8 的输出格式进行解析(位置、类别、置信度等)
    auto boxes = output.slice(2, 0, 4);  // 获取边界框
    auto scores = output.slice(2, 4, 5);  // 获取置信度
    auto classes = output.slice(2, 5, 6); // 获取类别

    // 后处理: 解析并显示结果
    std::vector<cv::Rect> detected_boxes;
    std::vector<float> detected_scores;
    
    for (int i = 0; i < boxes.size(0); ++i) {
        // 处理边界框、置信度等(这里根据实际输出进行适配)
        detected_boxes.push_back(cv::Rect(
            boxes[i][0].item<int>(), 
            boxes[i][1].item<int>(), 
            boxes[i][2].item<int>(), 
            boxes[i][3].item<int>()
        ));
        detected_scores.push_back(scores[i].item<float>());
    }

    // 显示检测结果
    showResults(img, detected_boxes, detected_scores);

    return 0;
}
```

编译和运行程序

使用以下命令编译和运行 C++ 程序: 


确保你将 yolov8_torchscript.pt 和 input.jpg 文件放在合适的位置, 并在 C++ 中正确地设置了模型路径和图像路

步骤 4: 结果

程序会加载 YOLOv8 模型, 对输入的图片进行推理, 并在检测到的物品周围绘制边界框并显示物品类别和置信度

注意事项

后处理: YOLOv8 模型的输出需要根据模型的具体格式进行后处理

需要根据 YOLOv8 输出的类别和框的格式调整后处理代码, 通常输出的格式为 (num_boxes, 85), 其中包含了边界框的坐标、置信度和类别等信息

在 C++ 中使用 libtorch 进行推理时需要确保正确安装了 libtorch 和 OpenCV, 并且设置了合适的 CMake 配置

通过上述步骤, 应该可以成功地在 C++ 中加载 YOLOv8 模型并进行物品识别